{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "backed-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "median-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modeli daha hızlı eğitmek için CPU yerine GPU seçtik. Bunun uygulanabilmesi için birkaç program indirilmesi gerekmektedir.\n",
    "# Gerekenlere buradan ulaşabilirsiniz: https://www.tensorflow.org/install/gpu\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cordless-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35126\n",
      "converted_images\\0-NoDR\\10003_left.jpeg\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(\"./converted_images\")\n",
    "image_count = len(list(data_dir.glob('*/*.jpeg')))\n",
    "print(image_count)\n",
    "NoDR = list(data_dir.glob('0-NoDR/*'))\n",
    "print(str(NoDR[0]))\n",
    "#PIL.Image.open(str(NoDR[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grand-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 192\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "knowing-baseball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35126 files belonging to 5 classes.\n",
      "Using 24589 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"training\",\n",
    "  seed=142,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "angry-armor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35126 files belonging to 5 classes.\n",
      "Using 10537 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"validation\",\n",
    "  seed=142,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gross-stage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-NoDR', '1-Mild', '2-Moderate', '3-Severe', '4-ProliferativeDR']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "signal-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "studied-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "static-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)), # Fotoğrafı yatay eksende rastgele bir şekilde döndürüyor.\n",
    "    layers.RandomRotation(0.1), # Fotoğrafa rastgele bir rotasyon ekliyor.\n",
    "    layers.RandomZoom(0.1), # Fotoğrafı rastgele boyutta büyütüp küçültüyor\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "golden-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "basic-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names) # Kaç tane sınıfımızın olduğunu tutuyoruz\n",
    "model = Sequential([ # Sequential model en basit modeldir. Kolayca katman eklememizi sağlar\n",
    "  data_augmentation, # Bir önceki kod parçacığındaki fotoğraf döndürme işlemi\n",
    "  #layers.Rescaling(1./255), # Piksel değerlerini [0 255] aralığından [0 1] aralığına indirgiyoruz\n",
    "  layers.Grayscale(output_channels=1)\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(img_height, img_width, 3)), # Relu aktivasyonlu Conv2D katmanı\n",
    "  layers.MaxPooling2D(), # MaxPooling2D ile veri havuzunun boyutunu küçültüyoruz.\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'), # Relu aktivasyonlu Conv2D katmanı\n",
    "  layers.MaxPooling2D(), # MaxPooling2D ile veri havuzunun boyutunu küçültüyoruz.\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'), # Relu aktivasyonlu Conv2D katmanı\n",
    "  layers.MaxPooling2D(), # MaxPooling2D ile veri havuzunun boyutunu küçültüyoruz.\n",
    "  #layers.Conv2D(128, 3, padding='same', activation='relu'), # Relu aktivasyonlu Conv2D katmanı\n",
    "  #layers.MaxPooling2D(), # MaxPooling2D ile veri havuzunun boyutunu küçültüyoruz.\n",
    "  #layers.Dropout(0.2), # Aşırı uyumu engellemek için belli değerleri düşürüyoruz.\n",
    "  layers.Flatten(), # Matris formundaki veriyi düzleştirmek için kullanılır\n",
    "  layers.Dense(128, activation='sigmoid'), # Dense çoğu durumda çalışan standart bir katman türüdür. Yoğun bir katmanda, önceki katmandaki tüm düğümler mevcut katmandaki düğümlere bağlanır\n",
    "  layers.Dense(num_classes) # Dense çoğu durumda çalışan standart bir katman türüdür. Yoğun bir katmanda, önceki katmandaki tüm düğümler mevcut katmandaki düğümlere bağlanır\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ancient-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "juvenile-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decent-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy'] # Eğitim doğruluğunun değerlerini alıyoruz\n",
    "val_acc = history.history['val_accuracy'] # Doğrulama doğruluğunun değerlerini alıyoruz\n",
    "\n",
    "loss = history.history['loss'] # Eğitim kayıp verisini alıyoruz\n",
    "val_loss = history.history['val_loss'] # Doğrulama kayıp verisini alıyoruz\n",
    "\n",
    "epochs_range = range(epochs) # 0'dan [paket sayısı - 1]'e kadar bir dizi oluşturuyoruz [0, 1, ..., epochs - 1]\n",
    "\n",
    "plt.figure(figsize=(8, 8)) # 8'e 8 boyutlu bir figür oluşturuyoruz\n",
    "plt.subplot(1, 2, 1) # Doğruluk verisini içerek ilk parçayı ayırıyoruz\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy') # Eğitim doğruluğunun grafiğini çiziyoruz\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy') # Doğrulama doğruluğunun grafiğini çiziyoruz\n",
    "plt.legend(loc='lower right') # Legend yazısını sağ alta alıyoruz\n",
    "plt.title('Training and Validation Accuracy') # Başlığı ayarlıyoruz\n",
    "\n",
    "plt.subplot(1, 2, 2) # Kayıp verisini içeren ikinci parçayı ayırıyoruz\n",
    "plt.plot(epochs_range, loss, label='Training Loss') # Eğitim kaybının grafiğini çiziyoruz\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss') # Doğruluk kaybının grafiğini çiziyoruz\n",
    "plt.legend(loc='upper right') # Legend yazısını sağ üste alıyoruz\n",
    "plt.title('Training and Validation Loss') # Başlığı ayarlıyoruz\n",
    "plt.show() # Grafiklerimizi gösteriyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-immigration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
